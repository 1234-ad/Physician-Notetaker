{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8712bffb",
   "metadata": {},
   "source": [
    "# 🩺 Physician Notetaker - Interactive Demo\n",
    "\n",
    "This notebook demonstrates all features of the Physician Notetaker system:\n",
    "1. **Medical NLP Summarization** - Extract medical entities, summarize conversations\n",
    "2. **Sentiment & Intent Analysis** - Analyze patient emotions and intentions\n",
    "3. **SOAP Note Generation** - Generate structured clinical notes\n",
    "\n",
    "## Setup\n",
    "First, let's import all necessary modules and initialize the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878eff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our modules\n",
    "from src.medical_nlp import MedicalNLPProcessor\n",
    "from src.sentiment_analysis import SentimentIntentAnalyzer\n",
    "from src.soap_generator import SOAPNoteGenerator\n",
    "from config import SAMPLE_CONVERSATION\n",
    "\n",
    "print(\"✅ Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all components\n",
    "print(\"Initializing Medical NLP Processor...\")\n",
    "nlp_processor = MedicalNLPProcessor()\n",
    "\n",
    "print(\"\\nInitializing Sentiment Analyzer...\")\n",
    "sentiment_analyzer = SentimentIntentAnalyzer()\n",
    "\n",
    "print(\"\\nInitializing SOAP Generator...\")\n",
    "soap_generator = SOAPNoteGenerator()\n",
    "\n",
    "print(\"\\n✅ All components initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d547d96",
   "metadata": {},
   "source": [
    "## Sample Conversation\n",
    "\n",
    "Let's view the sample physician-patient conversation we'll be analyzing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93198bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SAMPLE MEDICAL CONVERSATION\")\n",
    "print(\"=\" * 80)\n",
    "print(SAMPLE_CONVERSATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d6e29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1️⃣ Medical NLP Summarization\n",
    "\n",
    "Extract key medical details including:\n",
    "- Named Entity Recognition (NER)\n",
    "- Text Summarization\n",
    "- Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate structured medical summary\n",
    "print(\"📋 STRUCTURED MEDICAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "medical_summary = nlp_processor.generate_structured_summary(SAMPLE_CONVERSATION)\n",
    "print(json.dumps(medical_summary, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract medical entities\n",
    "print(\"🔍 EXTRACTED MEDICAL ENTITIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "entities = nlp_processor.extract_entities(SAMPLE_CONVERSATION)\n",
    "\n",
    "for entity_type, items in entities.items():\n",
    "    if items:\n",
    "        print(f\"\\n{entity_type.upper()}:\")\n",
    "        for item in items:\n",
    "            print(f\"  • {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3745b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords\n",
    "print(\"🔑 MEDICAL KEYWORDS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "keywords = nlp_processor.extract_keywords(SAMPLE_CONVERSATION)\n",
    "print(\"\\nTop Medical Keywords:\")\n",
    "for keyword, score in keywords[:10]:\n",
    "    print(f\"  • {keyword}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle ambiguous data\n",
    "print(\"⚠️  AMBIGUOUS DATA HANDLING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ambiguous_result = nlp_processor.handle_ambiguous_data(SAMPLE_CONVERSATION)\n",
    "\n",
    "print(\"\\nConfidence Scores:\")\n",
    "for field, score in ambiguous_result['confidence_scores'].items():\n",
    "    status = \"✅\" if score >= 0.7 else \"⚠️\"\n",
    "    print(f\"  {status} {field}: {score:.2f}\")\n",
    "\n",
    "if ambiguous_result['low_confidence_fields']:\n",
    "    print(f\"\\nLow Confidence Fields: {', '.join(ambiguous_result['low_confidence_fields'])}\")\n",
    "    print(\"\\nRecommendations:\")\n",
    "    for rec in ambiguous_result['recommendations']:\n",
    "        print(f\"  • {rec}\")\n",
    "else:\n",
    "    print(\"\\n✅ All fields have high confidence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c6e75",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2️⃣ Sentiment & Intent Analysis\n",
    "\n",
    "Analyze patient sentiment and detect their intentions throughout the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test individual patient statements\n",
    "print(\"😊 PATIENT STATEMENT ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_statements = [\n",
    "    \"I'm a bit worried about my back pain, but I hope it gets better soon.\",\n",
    "    \"Good morning, doctor. I'm doing better, but I still have some discomfort now and then.\",\n",
    "    \"The first four weeks were rough. My neck and back pain were really bad.\",\n",
    "    \"That's a relief!\",\n",
    "    \"Thank you, doctor. I appreciate it.\"\n",
    "]\n",
    "\n",
    "for i, statement in enumerate(test_statements, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Statement {i}: \\\"{statement}\\\"\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    result = sentiment_analyzer.analyze_patient_dialogue(statement)\n",
    "    \n",
    "    # Display sentiment with emoji\n",
    "    sentiment_emoji = {\n",
    "        'Anxious': '😰',\n",
    "        'Neutral': '😐',\n",
    "        'Reassured': '😊'\n",
    "    }\n",
    "    \n",
    "    emoji = sentiment_emoji.get(result['Sentiment'], '😐')\n",
    "    print(f\"  {emoji} Sentiment: {result['Sentiment']} (Confidence: {result['Sentiment_Confidence']})\")\n",
    "    print(f\"  🎯 Intent: {result['Intent']} (Confidence: {result['Intent_Confidence']})\")\n",
    "    \n",
    "    if result['Secondary_Intents']:\n",
    "        print(f\"  📌 Secondary Intents: {', '.join(result['Secondary_Intents'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze full conversation\n",
    "print(\"\\n\\n📊 FULL CONVERSATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "conversation_summary = sentiment_analyzer.get_conversation_summary(SAMPLE_CONVERSATION)\n",
    "\n",
    "print(f\"\\nTotal Patient Statements: {conversation_summary['Total_Patient_Statements']}\")\n",
    "print(f\"Overall Sentiment: {conversation_summary['Overall_Sentiment']}\")\n",
    "print(f\"Most Common Intent: {conversation_summary['Most_Common_Intent']}\")\n",
    "\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "for sentiment, count in conversation_summary['Sentiment_Distribution'].items():\n",
    "    bar = '█' * count\n",
    "    print(f\"  {sentiment:12s}: {bar} ({count})\")\n",
    "\n",
    "print(\"\\nIntent Distribution:\")\n",
    "for intent, count in conversation_summary['Intent_Distribution'].items():\n",
    "    bar = '█' * count\n",
    "    print(f\"  {intent:25s}: {bar} ({count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b73f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment over time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "analyses = conversation_summary['Detailed_Analysis']\n",
    "\n",
    "sentiments_order = [a['Sentiment'] for a in analyses]\n",
    "sentiment_map = {'Anxious': 1, 'Neutral': 2, 'Reassured': 3}\n",
    "sentiment_values = [sentiment_map.get(s, 2) for s in sentiments_order]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(range(1, len(sentiment_values) + 1), sentiment_values, marker='o', linewidth=2, markersize=8)\n",
    "plt.yticks([1, 2, 3], ['Anxious', 'Neutral', 'Reassured'])\n",
    "plt.xlabel('Patient Statement Number')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Patient Sentiment Throughout Conversation')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📈 Sentiment trend shows patient's emotional journey during consultation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d457b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3️⃣ SOAP Note Generation (Bonus)\n",
    "\n",
    "Generate a structured SOAP (Subjective, Objective, Assessment, Plan) note from the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc6175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SOAP note\n",
    "print(\"📝 SOAP NOTE GENERATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "soap_note = soap_generator.generate_soap_note(SAMPLE_CONVERSATION)\n",
    "print(json.dumps(soap_note, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display SOAP note in formatted text\n",
    "print(\"\\n📋 FORMATTED SOAP NOTE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n[S] SUBJECTIVE\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Chief Complaint: {soap_note['Subjective']['Chief_Complaint']}\")\n",
    "print(f\"\\nHistory of Present Illness:\")\n",
    "print(f\"  {soap_note['Subjective']['History_of_Present_Illness']}\")\n",
    "\n",
    "print(\"\\n[O] OBJECTIVE\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Physical Exam: {soap_note['Objective']['Physical_Exam']}\")\n",
    "print(f\"Observations: {soap_note['Objective']['Observations']}\")\n",
    "\n",
    "print(\"\\n[A] ASSESSMENT\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Diagnosis: {soap_note['Assessment']['Diagnosis']}\")\n",
    "print(f\"Severity: {soap_note['Assessment']['Severity']}\")\n",
    "if 'Additional_Notes' in soap_note['Assessment']:\n",
    "    print(f\"Notes: {soap_note['Assessment']['Additional_Notes']}\")\n",
    "\n",
    "print(\"\\n[P] PLAN\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Treatment:\")\n",
    "for treatment in soap_note['Plan']['Treatment']:\n",
    "    print(f\"  • {treatment}\")\n",
    "print(f\"\\nFollow-Up: {soap_note['Plan']['Follow_Up']}\")\n",
    "if 'Patient_Education' in soap_note['Plan']:\n",
    "    print(f\"Patient Education: {soap_note['Plan']['Patient_Education']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69c8f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🎯 Complete Analysis Report\n",
    "\n",
    "Let's generate a comprehensive report combining all analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate complete report\n",
    "from main import PhysicianNotetaker\n",
    "\n",
    "print(\"🩺 COMPREHENSIVE MEDICAL ANALYSIS REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "app = PhysicianNotetaker()\n",
    "complete_results = app.process_conversation(SAMPLE_CONVERSATION)\n",
    "\n",
    "# Save to file\n",
    "app.save_results(complete_results, 'analysis_results.json')\n",
    "print(\"\\n💾 Complete results saved to: analysis_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24125c2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🧪 Try Your Own Conversation\n",
    "\n",
    "You can test the system with your own medical conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64757ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom conversation input\n",
    "custom_conversation = \"\"\"\n",
    "Doctor: How are you feeling today?\n",
    "Patient: I had a car accident. My neck and back hurt a lot for four weeks.\n",
    "Doctor: Did you receive treatment?\n",
    "Patient: Yes, I had ten physiotherapy sessions, and now I only have occasional back pain.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Analyzing custom conversation...\\n\")\n",
    "\n",
    "# Quick analysis\n",
    "custom_summary = nlp_processor.generate_structured_summary(custom_conversation)\n",
    "custom_soap = soap_generator.generate_soap_note(custom_conversation)\n",
    "\n",
    "print(\"Medical Summary:\")\n",
    "print(json.dumps(custom_summary, indent=2))\n",
    "\n",
    "print(\"\\n\\nSOAP Note:\")\n",
    "print(json.dumps(custom_soap, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29706be1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📚 Answers to Technical Questions\n",
    "\n",
    "## Question 1: Handling Ambiguous or Missing Medical Data\n",
    "\n",
    "**Approach:**\n",
    "1. **Confidence Scoring**: Assign confidence scores to each extracted field\n",
    "2. **Multiple Evidence Sources**: Use pattern matching + NER + contextual analysis\n",
    "3. **Flagging Low Confidence**: Alert when data quality is below threshold\n",
    "4. **Recommendations**: Provide actionable suggestions for verification\n",
    "\n",
    "## Question 2: Pre-trained NLP Models for Medical Summarization\n",
    "\n",
    "**Recommended Models:**\n",
    "- **SciBERT / BioClinicalBERT**: Medical domain pre-training\n",
    "- **SciSpacy**: Medical NER and entity linking\n",
    "- **BART / T5**: Abstractive summarization\n",
    "- **DistilBERT**: Efficient sentiment analysis\n",
    "\n",
    "## Question 3: Fine-tuning BERT for Medical Sentiment\n",
    "\n",
    "**Process:**\n",
    "1. Start with BioClinicalBERT (medical domain)\n",
    "2. Collect labeled patient conversations (5K-10K examples)\n",
    "3. Fine-tune with learning rate 2e-5, 3-5 epochs\n",
    "4. Use medical-specific sentiment labels: Anxious, Neutral, Reassured\n",
    "5. Validate with clinical experts\n",
    "\n",
    "## Question 4: Datasets for Healthcare Sentiment Model\n",
    "\n",
    "**Recommended Datasets:**\n",
    "- MedDialog (medical conversations)\n",
    "- MIMIC-III Clinical Notes\n",
    "- Custom annotated patient conversations\n",
    "- Reddit medical communities (with proper annotation)\n",
    "\n",
    "## Question 5: Training NLP for SOAP Format\n",
    "\n",
    "**Approach:**\n",
    "1. **Sequence-to-Sequence Model**: T5 or BART for generation\n",
    "2. **Section Classification**: BERT to classify sentences into SOAP sections\n",
    "3. **Template-based**: Rules + NER for structured output\n",
    "4. **Hybrid**: Combine deep learning entity extraction with rule-based structuring\n",
    "\n",
    "## Question 6: Improving SOAP Note Generation Accuracy\n",
    "\n",
    "**Techniques:**\n",
    "- **Rule-based constraints**: Enforce SOAP structure\n",
    "- **Entity preservation**: Ensure medical terms are not lost\n",
    "- **Multi-task learning**: Train on section classification + generation simultaneously\n",
    "- **Post-processing**: Validate with medical ontologies (UMLS, SNOMED)\n",
    "- **Expert validation**: Clinical review and feedback loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6f3ed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ✅ Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ✅ Medical NLP with entity extraction and summarization\n",
    "2. ✅ Sentiment analysis detecting patient emotional states\n",
    "3. ✅ Intent detection identifying patient communication goals\n",
    "4. ✅ SOAP note generation for clinical documentation\n",
    "5. ✅ Comprehensive quality checking with confidence scores\n",
    "\n",
    "## Next Steps:\n",
    "- Fine-tune models on medical datasets\n",
    "- Add more entity types (medications, dosages, etc.)\n",
    "- Implement real-time transcription integration\n",
    "- Add multi-language support\n",
    "- Deploy as web API using FastAPI"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
